Peer Assessment Assignment
==========================

Coursera _Getting and Cleaning Data_ class           

Preliminaries
-------------
The purpose of the project was to collect, work with, and clean the dataset related to the project [Human Activity Recognition Using Smartphones Data Set](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).

The file **getdata\_projectfiles\_UCI HAR Dataset.zip** was downloaded from the class site and a directory structure with files were unzipped into the **UCI HAR Dataset** directory.

Files in the unzipped directory included a **README.txt** with general information, and two files describing the features in the data, **features.txt** and **feature\s_info.txt**.  An **activity\_labels.txt** file gave text descriptions for the six activities that were studied.

**test** and **train** subdirectories each had three files and an **Inertial Signals** directory.  As described in the README.txt file, The **subject_xxxx.txt** files defined the subject ids and the **y_xxxx.txt** files defined the activities for which measurments were made and recorded in the **X_xxx.txt** files.  The **xxxx** in these filenames was either **test** or **train**.

The raw data in the **Inertial** directories were not needed for the programming assignment.

First Look
----------

The script **0-First-Look.R** was used to experiment with and understand the data.  The script was re-written and became the script **run\_analysis.R**, which was submitted as part of the assignment.

The run\_analysis.R script
--------------------------

The following output from *knitr* shows many of the R statements in this script along with output to explain how it processed the data in BASEDIR from the unzipped file:


```{r}
BASEDIR <- "C:/2014/Getting-Cleaning-Data/UCI HAR Dataset"
setwd(BASEDIR)

Activity.Names <- c("Walk", "WalkUp", "WalkDown", "Sit", "Stand", "Lying")      
```

The helper function `readGroup` reads the _train_ and _test_ files.

Note this comment below marks one of the assigned tasks:
__3. Use descriptive activity names to name the activities in the dataset__ 

```{r}
readGroup <- function(BASEDIR, GROUP)
{
  # Read subject_GROUP.txt file (GROUP is "test" or "train")
  filename <- paste0(BASEDIR, "/", GROUP, "/subject_", GROUP, ".txt")
  subject.id <- as.numeric(readLines(filename))

  # y_GROUP.txt file with labels
  filename <- paste0(BASEDIR, "/", GROUP, "/y_", GROUP, ".txt")
  activity.index <- as.numeric(readLines(filename))

  stopifnot(length(subject.id) == length(activity.index))

  # X_GROUP.txt file with feature data
  filename <- paste0(BASEDIR, "/", GROUP, "/X_", GROUP, ".txt")
  # All records are 8976 bytes wide.  Each field takes 16 bytes.
  # Therefore, must be 8976 / 16 = 561 columns = expected number of features.
  x <- scan(filename)                   # fast way to parse very regular file
  dim(x) <- c(561, length(subject.id))  # Want a matrix
  y <- t(x)                             # Really want transpose of matrix

  # Note conversion of activity.index to descriptive name below to:
  # "3. Use descriptive activity names to name the activities in the dataset"

  GROUP.data <- data.frame(source=GROUP,   # test or train
                           subject.id=subject.id,
                           activity=Activity.Names[activity.index],
                           y,   # deal with column names later
                           stringsAsFactors=FALSE)
  invisible(GROUP.data)
}                                                    
```

`readGroup` combines data from three files for the `test` and `train` groups and returns a data.frame.  `readGroup` converts the activity indices to descriptive words using a simple subscript lookup as the data.frame is defined.


Loading the test and train data is as easy as two calls to `readGroup`:

```{r}
test.data  <- readGroup(BASEDIR, "test")
dim(test.data)

train.data <- readGroup(BASEDIR, "train")
dim(train.data)      
```

Per instructions (__1. Merge the training and test sets to create one dataset__), the _train_ and _test_ data were merged into a single dataset:

```{r}
combined.data <- rbind(test.data, train.data)
dim(combined.data) 
```
Let's cleanup feature names to be more R "friendly" (__4. Appropriately label the dataset with desciptive__ names):

```{r}
filename <- paste0(BASEDIR, "/features.txt")
feature.names <- read.table(filename, sep=" ", header=FALSE, as.is=TRUE)
feature.names <- feature.names$V2   # only want 2nd column

# Change "()" to "E" for "estimate" as in "estimated from these signals"
feature.names <- gsub("\\()", "E", feature.names)

# Remove dashes and commas
feature.names <- gsub("-|,", ".", feature.names)

# Fix angle data with paretheses. "(" -> ".". ")" -> ""
feature.names <- gsub("\\(", ".", feature.names)
feature.names <- gsub(")",   "",  feature.names)

# Prefix all names with vNNN. to maintain link to original documentation.
# (These can always be removed later if not wanted.)
feature.names <- sprintf("v%3.3d.%s", 1:length(feature.names),
                           feature.names)

names(combined.data)[4:ncol(combined.data)] <- feature.names   

head(feature.names)
tail(feature.names)   
```

The statements above replaced certain characters in the original feature names to make them more R friendly.  [This processing probably should have been performed first, and used in the `readGroup` function to name the columns in the "X" file.]


I could write the `combined.data` to disk if desired at this point.  The
instructions are ambiguous as to whether this is wanted.  Since the file is
huge (~64 MB), I'm electing NOT to create the file at this time.   

__2. Extract only the measurements on the mean and standard deviation ...__

Feature estimates for mean and standard deviation are represented in the
column names as meanE and stdE [since the () was replaced by "E" above].
In addition to the meanE and stdE columns, we also want columns 1:3, namely
source, subject.id and activity.

Adding additional columns to the subset would be easy through a modification of the `MeanStdExtrctColumns` object below.

```{r}
MeanStdExtractColumns <- c(1:3, grep("meanE|stdE", names(combined.data)))

MeanStdExtract <- combined.data[, MeanStdExtractColumns]
dim(MeanStdExtract) 
```

__5. Create a second, independent tidy dataset with the average of each
variable for each activity for each subject__ 

The `split` function breaks the original data into a list by subject and activity.

```{r}
splits <- split(MeanStdExtract, list(MeanStdExtract$subject.id,
                                     MeanStdExtract$activity))
length(splits)

#  x <- splits[[1]]

Tidy.Summary <- do.call(rbind, lapply(splits,
                  function(x)
                  {
                    data.frame(subject.id = x$subject.id[1],
                               activity   = x$activity[1],
                               t(colMeans(x[,-1:-3])),  # note transpose here
                               stringsAsFactors=FALSE)
                  }
                ))

# Order by subject.id and activity to see all activities for subject.id together.
Tidy.Summary <- Tidy.Summary[order(Tidy.Summary$subject.id, Tidy.Summary$activity),]

dim(Tidy.Summary)

# This file is the one to be submitted as part of the assignment
write.csv(Tidy.Summary, "Samsung-Tidy-Summary.csv", row.names=FALSE)       
```

The `do.call` function above looks a bit complicated, but it's fairly easy to develop.  After the `splits` are defined, one of the splits can be assigned to object `x` (which is commented out above), and used to develop a function that returns a data.frame.  I find this approach more flexible than options offered by the `plyr` package.

The `Tidy.Summary` object is sorted by subject and activity to group all activities for the same subject together.

The following shows descriptive stats with various frequency counts, which are useful for double-checking and analysis.

```{r}
table(combined.data$source)
table(combined.data$subject.id)
table(combined.data$activity)  
```

Number of records by activity by subject.id by source:
```{r}
table(combined.data$subject.id, combined.data$activity, combined.data$source)    
```

Code Book
---------

The "X" files contained 561 features from analysis of the Samsung data for 30 subjects and 6 activites. The 30 subjects were divided into **test* and **train** subsets in the original data. 

The **combined.data** object contained three labels and these 561 features for all 30 subjects and 6 activities.

The three labels for the combined.data include:
* **source** = "test" or "train" to easily extract a subset from `combined.data`.
* **subject.id** = subject number from 1 to 30
* **activity** = "Walk", "WalkUp", "WalkDown", "Sit", "Stand", "Lying"

The 561 feature variables were given R friendly names.  These names all started with vNNN, where NNN = 001 to 561.  The NNN is an index to find the data in the "X" file, or to find the unmodified name in the original **features.txt** file.

The following is a list of of data columns in the **Tidy.Summary** object, which were written to the **Samsung-Tidy-Summary.txt** file.


```{r}
names(MeanStdExtract)[-1]  
```

Here's how to interpret the "v" feature variables in this subset:

**vnnn.Signal.Stat[.Dimension]**

**Vnnn** = the nnn index keeps a linkage to the original data and documenation.  The "v" prefix for "variable" was used to make the names R "friendly".

**Signal** = 

  tBodyAcc-XYZ
  tGravityAcc-XYZ
  tBodyAccJerk-XYZ
  tBodyGyro-XYZ
  tBodyGyroJerk-XYZ
  tBodyAccMag
  tGravityAccMag
  tBodyAccJerkMag
  tBodyGyroMag
  tBodyGyroJerkMag
  fBodyAcc-XYZ
  fBodyAccJerk-XYZ
  fBodyGyro-XYZ
  fBodyAccMag
  fBodyAccJerkMag
  fBodyGyroMag
  fBodyGyroJerkMag   
  

The "t" or "f" prefix indicates whether the variable is part of a time series, or frequency data derived from Fourier analysis.

The "-XYZ" part of the name indicates which dimensions, X, Y and Z have separate variables.  Some quantities do not have dimensions.

See the file **features\_info.txt** for more information about the computed features.  [Sadly, the documentation does not provide sufficient information to reproduce the computed values from the raw data.]

**Stat** = meanE | stdE

Per the homework assignment, only the mean (mean) and standard deviation (std) estimated (E) values were included in the **Tidy.Summary** object.



efg, 2014-02-02